{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "işe_alım_destek_sistemi/\n",
    "│\n",
    "├── data/\n",
    "│   ├── resumes/          # Adayların özgeçmiş dosyaları\n",
    "│   ├── job_descriptions/ # İş ilanları\n",
    "│   └── processed/        # İşlenmiş veri dosyaları\n",
    "│\n",
    "├── models/\n",
    "│   ├── nlp_models/       # NLP modelleri\n",
    "│   └── ml_models/        # ML ve DL modelleri\n",
    "│\n",
    "├── src/\n",
    "│   ├── data_preprocessing.py\n",
    "│   ├── feature_extraction.py\n",
    "│   ├── model_training.py\n",
    "│   ├── resume_analysis.py\n",
    "│   └── job_matching.py\n",
    "│\n",
    "├── notebooks/\n",
    "│   ├── data_exploration.ipynb\n",
    "│   ├── model_evaluation.ipynb\n",
    "│   └── results_visualization.ipynb\n",
    "│\n",
    "├── app.py                # Ana uygulama dosyası\n",
    "├── requirements.txt\n",
    "└── README.md\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def load_data(resume_dir, job_dir):\n",
    "    resumes = []\n",
    "    for file in os.listdir(resume_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(resume_dir, file), 'r') as f:\n",
    "                resumes.append(f.read())\n",
    "    \n",
    "    job_descriptions = []\n",
    "    for file in os.listdir(job_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(job_dir, file), 'r') as f:\n",
    "                job_descriptions.append(f.read())\n",
    "    \n",
    "    return resumes, job_descriptions\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def preprocess_data(resumes, job_descriptions):\n",
    "    resumes = [preprocess_text(resume) for resume in resumes]\n",
    "    job_descriptions = [preprocess_text(job) for job in job_descriptions]\n",
    "    return resumes, job_descriptions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_dir = \"../data/resumes\"\n",
    "    job_dir = \"../data/job_descriptions\"\n",
    "    \n",
    "    resumes, job_descriptions = load_data(resume_dir, job_dir)\n",
    "    resumes, job_descriptions = preprocess_data(resumes, job_descriptions)\n",
    "    \n",
    "    resume_df = pd.DataFrame({'text': resumes, 'type': 'resume'})\n",
    "    job_df = pd.DataFrame({'text': job_descriptions, 'type': 'job_description'})\n",
    "    \n",
    "    df = pd.concat([resume_df, job_df], ignore_index=True)\n",
    "    df.to_csv(\"../data/processed/data.csv\", index=False)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def extract_features(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X = vectorizer.fit_transform(df['text'])\n",
    "    return X, df['type']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"../data/processed/data.csv\"\n",
    "    X, y = extract_features(data_path)\n",
    "    \n",
    "    from scipy.sparse import save_npz\n",
    "    save_npz(\"../data/processed/features.npz\", X)\n",
    "    y.to_csv(\"../data/processed/labels.csv\", index=False)\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "def train_model(features_path, labels_path):\n",
    "    X = load_npz(features_path)\n",
    "    y = pd.read_csv(labels_path)['type']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    features_path = \"../data/processed/features.npz\"\n",
    "    labels_path = \"../data/processed/labels.csv\"\n",
    "    model = train_model(features_path, labels_path)\n",
    "    \n",
    "    import joblib\n",
    "    joblib.dump(model, \"../models/ml_models/svm_model.joblib\")\n",
    "\n",
    "\n",
    "import spacy\n",
    "import joblib\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "model = joblib.load(\"../models/ml_models/svm_model.joblib\")\n",
    "\n",
    "def analyze_resume(resume_text):\n",
    "    doc = nlp(resume_text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def predict_resume_category(preprocessed_text):\n",
    "    return model.predict([preprocessed_text])[0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_text = \"Your resume text here.\"\n",
    "    preprocessed_text = analyze_resume(resume_text)\n",
    "    category = predict_resume_category(preprocessed_text)\n",
    "    print(f\"Predicted Category: {category}\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "def match_jobs(resume_features, job_features_path):\n",
    "    job_features = load_npz(job_features_path)\n",
    "    similarities = cosine_similarity(resume_features, job_features)\n",
    "    return similarities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_features_path = \"../data/processed/resume_features.npz\"\n",
    "    job_features_path = \"../data/processed/job_features.npz\"\n",
    "    \n",
    "    resume_features = load_npz(resume_features_path)\n",
    "    similarities = match_jobs(resume_features, job_features_path)\n",
    "    \n",
    "    job_df = pd.read_csv(\"../data/processed/job_descriptions.csv\")\n",
    "    top_jobs = job_df.iloc[similarities[0].argsort()[-5:][::-1]]\n",
    "    print(top_jobs)\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "from src.resume_analysis import analyze_resume, predict_resume_category\n",
    "from src.job_matching import match_jobs\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/analyze_resume', methods=['POST'])\n",
    "def analyze_resume_route():\n",
    "    data = request.get_json()\n",
    "    resume_text = data['resume_text']\n",
    "    preprocessed_text = analyze_resume(resume_text)\n",
    "    category = predict_resume_category(preprocessed_text)\n",
    "    return jsonify({'category': category})\n",
    "\n",
    "@app.route('/match_jobs', methods=['POST'])\n",
    "def match_jobs_route():\n",
    "    data = request.get_json()\n",
    "    resume_features_path = data['resume_features_path']\n",
    "    job_features_path = \"../data/processed/job_features.npz\"\n",
    "    \n",
    "    resume_features = load_npz(resume_features_path)\n",
    "    similarities = match_jobs(resume_features, job_features_path)\n",
    "    \n",
    "    job_df = pd.read_csv(\"../data/processed/job_descriptions.csv\")\n",
    "    top_jobs = job_df.iloc[similarities[0].argsort()[-5:][::-1]]\n",
    "    return top_jobs.to_json(orient=\"records\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
